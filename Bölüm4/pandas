# pandas numpy e alternatif olarak doğmamıştır. numpy ile yapamadığımız bazı şeyleri pandas ile yapabiliyoruz. bu yüzden hem numpy hemde pandas ı bilmek lazım.

import pandas as pd
kaho=pd.Series([78,9,5,4,5,6,18,45,7,99,566])
print(kaho) # görüldüğü üzere veriler index bilgisi ile yazıldı.
print(kaho.axes) # [RangeIndex(start=0, stop=11, step=1)]görüldüğü üzere axes ile index bilgisine eriştik. 0 dan başlayarak 5 e kadar 5 dahıl değil. ve  bir bir atlayarak göstermiş.
print(kaho.size) # eleman sayısını verir.
print(kaho.ndim)
print(kaho.dtype)
print(kaho.values) # değerleri  gösterir.
print(kaho.head()) # burda parantz içinde herhangi bir sayı yok ise ilk 5 eleman gösterilir.
print(kaho.head(3)) # ilk 3 eleman yazdırılır.
print(kaho.tail()) # son bir kaç elemana gözatmak için tail kullanılır. zaten ingilizcede o anlama gelir.
kaho1=pd.Series([78,9,45,656,879,35],index=[1,2,3,4,5,6])
print(kaho1) # görüldüğü üzere indexleri kendimizde belirleyebiliyoruz.
kaho2=pd.Series([78,9,45,656,879,35],index=["k","a","h","r","a","m"])
print(kaho2) # indexleri sayı olmayacak şekilde de yapabiliriz bu şekilde ki gibi.
print(kaho2["m"]) # karşılığı olan 35 cıkar. sözlük yapısı gibi düşüm burayı.
print(kaho2["k":"h"]) # bu şekilde slice işlemi de yapılabilir.



#sözlük üzerinden liste oluşturmak
import pandas as pd
j=pd.Series({"fare":"kucuk","inek":"buyuk","keci":"orta"})
print(j)

# alt saturda concat fonksiyonu birleştirmeye yarar.
print(pd.concat([j,j])) 

# eleman işlemleri:
#aşagıdakı ıslemler sayesınde numpyı panasa cevırdık
import numpy as np
j2=np.array([3,4,5,8,89,6,5,4,34])
j3=pd.Series(j2)
print(j3)
# j.index indexleri verir.
print(j.index) # Index(['fare', 'inek', 'keci'], dtype='object')
print(j.values) # ['kucuk' 'buyuk' 'orta'] sadece değerlere ulaştık bu sayede.
print(list(j.items())) # [('fare', 'kucuk'), ('inek', 'buyuk'), ('keci', 'orta')] boylece elemanlara eriştik.








#sözlük üzerinden liste oluşturmak
import pandas as pd
j=pd.Series({"fare":"kucuk","inek":"buyuk","keci":"orta"})
print(j)

# alt saturda concat fonksiyonu birleştirmeye yarar.
print(pd.concat([j,j])) 

# eleman işlemleri:
#aşagıdakı ıslemler sayesınde numpyı panasa cevırdık
import numpy as np
j2=np.array([3,4,5,8,89,6,5,4,34])
j3=pd.Series(j2)
print(j3)
# j.index indexleri verir.
print(j.index) # Index(['fare', 'inek', 'keci'], dtype='object')
print(j.values) # ['kucuk' 'buyuk' 'orta'] sadece değerlere ulaştık bu sayede.
print(list(j.items())) # [('fare', 'kucuk'), ('inek', 'buyuk'), ('keci', 'orta')] boylece elemanlara eriştik.



# eleman sorgulama:
j2=np.array([3,4,5,8,89,6,5,4,34])
print(4 in j2)  # bu yapı soyle der: j2 içinde 4 var mı?
  

import pandas as pd
j=pd.Series({"fare":"kucuk","inek":"buyuk","keci":"orta"})
#asagıdakı satırda fancy ile elemanlara eriştik.
print(j[["fare","keci"]])






import pandas as pd
#Dataframe excel gibi düşünebilirsin. veriyi excel formatına dönüştürüyor.
j4=[5,521,321,5465,8968,43512,13,654,321,564]
j5=pd.DataFrame(j4)
print(j5)
print(pd.DataFrame(j4,columns=["kahraman"])) # columns yazarak değişken atabiliyoruz.


import numpy as np
j6=np.arange(0,20).reshape(5,4)
j7=pd.DataFrame(j6,columns=["a","b","c","d"])
print(j7) # sutunların ustune degiskenlerini atadık.

print(j7.head(3)) # ilk 3 tanesini gösterdim.
print(j7.tail(2))
print(j7.columns) # Index(['a', 'b', 'c', 'd'], dtype='object') burada sütunların üstündeki ni çağırdık.


j7.columns=["q","w","r","t"] # böylece üstünde kilerin isimlerideğiştirebildik
print(j7)
print(j7.axes) # [RangeIndex(start=0, stop=5, step=1), Index(['q', 'w', 'r', 't'], dtype='object')]
print(type(j7)) # <class 'pandas.core.frame.DataFrame'>
print(j7.shape) # (5, 4)
print(j7.values) # liste seklınde array cıktı. pekı j7.array type nedir asagıda kı satırda
print(type(j7.values)) # <class 'numpy.ndarray'> gordugun gıbı array oldugu ıcın pandas degıl numpy dedı.






# sozluk uzerınden DataFrame oluşturma.
import numpy as np
v1=np.random.randint(5,size=3)
v2=np.random.randint(6,size=3)
v3=np.random.randint(10,size=3)


sozluk={"bayram":v1,
        "kahraman":v2,
        "onurhan":v3}
pd=pd.DataFrame(sozluk)
print(pd)
print(pd[0:2])
print(pd.ndim)
print(pd.shape)
print(pd.size)


# asagıda kı satırlarda gorulecegı uzere bu sekılde ındex kısmını ıstedıgımız gıbı degıstırdık.
print(pd.index)
pd.index=[2,5,8]
print(pd)






# SATIR VE SÜTUN BAZINDA SİLME:
import pandas as pd
import numpy as np
v1=np.random.randint(5,size=3)
v2=np.random.randint(6,size=3)
v3=np.random.randint(10,size=3)
sozluk={"bayram":v1,
        "kahraman":v2,
        "onurhan":v3}

q=pd.DataFrame(sozluk, index=["a","b","c"])
print(q)
print(q.drop("kahraman",axis=1)) # sütun bazında kahramanın sütunu sildi goruldugu uzere.
print(q.drop("b",axis=0)) # axis sıfır ise satırdan silmeye başalr. axis 1 ise sütun olarak silme işlemi yapar. 
print(q.drop("c",axis=0))
#AMA YUKARDA YAPTIĞIMIZ KALICI SİLME İŞLEMLERİ DEĞİL. KALICI YAPMAK İSTİYORSAK İNSPLACE KULLANILIR.
print(q)
# print(q.drop("a",axis=0,inplace=True))
print(q) # görüldüğü üzere kalıcı silme işlemi yaptık. yukardaki satırla.

#diyelim ki aynı anda bır den cok ındexı sılmek ıstıyoruz. o zman fanc kullanmalıyız.
l=["bayram","onurhan"]
print(q.drop(l,axis=1)) # fancy ile silme işlemi yaptırdık. boylece coklu sutun slme ya da satır sılme işlemi yapılabılır.
print(q)


#değişken için sorgulama işlemleri:
# "?" in q dediğimiz zaman ? q içinde var mı diye somuş oluyoruz.
print("bayram" in q) # oldugu ıcın True dedi

kğ=["kahraman","bayram","onurhan","kaho"]
for m in kğ:
    print(m in q)


#╚değişken eklem dırek boyle olur. bakar eger o degısken yoksa dırek ekler.
q["mert"]=[4,5,6]
print(q)
q["kahraman"]=[1,2,3] #{ var olan değişkeni değişterebilirsin bu sayede.}
print(q)

#değişkene işlemler yapma:
khj=q["kahraman"]*q["onurhan"]
print(khj)








# loc and iloc:
import numpy as np
import pandas as pd
t1=np.random.randint(0,50,size=5)
t2=np.random.randint(100,200,size=5)
t3=np.random.randint(200,1000,size=(5))
t6=np.random.randint(2000,120000,size=(5))
t5=[t1,t2,t3,t6]
t4=pd.DataFrame(t5,columns=["a","b","c","d","e"],index=["x","y","z","t"])
print(t4)
# loc and iloc:
# loc: istedıgımız ındexı oraya kadar goturur.ama iloc ise sondan bır eksık. mesela her ıkısnıne [0:3] yazdım locta 0,1,2,3, cıkarken loc ta ıse 0,1,2 cıkar.
# loc veri yapında ki verdiğin index isimlerine göre giderken iloc ise ona bakmadan direk int ndex kullanır. yani sen indexe ne dersen de o kendi index sayacaına göre gidecektir.
print(t4.loc["x":,"c"])
print(t4.iloc[0:,2])
# eger ki iloc ile degısken ısmını yazarak yazdırmak ıstıyorsan alt satırıda kı yontemı kullan.
print(t4.iloc[0:]["c"])
print(t4.loc["x":"t"])
print(t4.iloc[0:3]) # 65 ve 66. satırlar aynı sonucu verir.
print(t4.loc["x":"z","a":"c"])
print(t4.iloc[0:2,0:4])











import pandas as pd
import numpy as np

p1=np.random.randint(0,20,5)
p2=np.random.randint(10,50,5)
p3=np.random.randint(14,200,5)
p4=np.random.randint(14,2000,5)
p5=np.random.randint(14,2900,5)
p6=[p1,p2,p3,p4,p5]
p7=pd.DataFrame(p6,columns=["a","b","c","d","e"])
print(p7)
# alt iki satır aynı aslında yazılıslara dıkkat.
print(p7["a"])
print(p7.a)
print(p7.a>15) # her deger ıcın dener ve true ve false der.
# 0    False
# 1    False
# 2     True
# 3     True
# 4     True

print(p7[p7.a>15]) # dataframe de a değişkenınde 15 ten buyuk olan elemanları fıltreledı. ama sadece a degıskenı ıcın yaptı bunu. ve tum dataframe gosterıldı. eger sadece a degerlerını gormek ıstıyorsan ek olarak alt satırda kı gıbı yapmalısın.
#       a     b     c     d     e
# 1    42    19    27    11    16
# 2    54    98   169   185    62
# 3  1898    24    75   221  1692
# 4  1315  1350  1942  1687   243

# yukarda yıne a yı fıltreledık ama dataframe ıcınde. asagıda ıse sadece a degerlerını aldık.
print(p7[p7.a>15]["a"])
# 1      42
# 2      54
# 3    1898
# 4    1315



print(p7[(p7.a>15) & (p7.c>15)]) # hem a ve hem c ıcın 15 ten buyuk degerlerı fıltreledık.
#       a     b     c     d     e
# 2   138   110   171   167   162
# 3  1049  1224   849  1731  1370
# 4   716  2857  1662  1040  2184


print(p7.loc[p7.a>15,["a","b"]]) # loc olmaz ise hata verir. bu yuzden burada fancy ıle ıslme yapılmalı. ya da ilk basa loc eklersen hata engellenır.
rt=["a","b"]
print(p7.loc[p7.a>15,rt]) # fancy kullandık.,



#DataFrame birleştirme
p8=p7+50 # p8 p7 nin elemanlarına 0 eklenmiş hali oldu.
print(p7)
print(p8)
# birleştirme:
p9=pd.concat([p7,p8])
print(p9) # görüldüğü üzere birleşti ama index bazın da guzel olmayan bırlesme oldu. 4 e kadar gıttıkten sonra tekrar 4 e kadar gıtt. pekı bız bastan dırek 9 a kafar yapmak ıcın ne yapmalıyız onu asagıda kı satırlarda belırtecegım.
#      a    b    c     d     e
# 0    9    0   14    19    10
# 1   36   37   22    27    11
# 2  127  100  141    68   128
# 3  633  565  383  1106  1957
# 4  883  412  628   990  2771
# 0   59   50   64    69    60
# 1   86   87   72    77    61
# 2  177  150  191   118   178
# 3  683  615  433  1156  2007
# 4  933  462  678  1040  2821


p10=pd.concat([p7,p8],ignore_index=True)
print(p10) #  goruldugu uzere ındexler tekralamadan ardısık gıttı.
#       a     b     c     d    e
# 0    18     6     5     4    6
# 1    23    31    29    21   18
# 2    83    82    38    73  115
# 3  1137  1525  1769  1749  460
# 4  2667   761   810  2065  210
# 5    68    56    55    54   56
# 6    73    81    79    71   68
# 7   133   132    88   123  165
# 8  1187  1575  1819  1799  510
# 9  2717   811   860  2115  260


p7.columns=(["a","b","c","d","sayı5"]) # p8 dataframe de degıskenlerın bır tanesını farklı yaptık.
print(p7)
p10=pd.concat([p7,p8],ignore_index=True)
print(p10) # görüldüğü üzere her iki birleştirdiklerimizin değişken isimlerinden bir tanesi farklı olsa bu sekılde hata verecek sekılde bırlestırır sacma bır sekılde. 
# bu yuzden join="iner" kullanılır ortak degıskenler ıle bırlestırır.
#       a     b     c     d   sayı5       e
# 0     1    11    13    10     3.0     NaN
# 1    40    49    47    27    41.0     NaN
# 2   133    68   196   109   166.0     NaN
# 3  1425  1920  1080  1123  1023.0     NaN
# 4  2563  2561  1072  2038  1387.0     NaN
# 5    51    61    63    60     NaN    53.0
# 6    90    99    97    77     NaN    91.0
# 7   183   118   246   159     NaN   216.0
# 8  1475  1970  1130  1173     NaN  1073.0
# 9  2613  2611  1122  2088     NaN  1437.0



print(pd.concat([p7,p8],join="inner",ignore_index=True))  # gorüldüğü üzere ortak olan a,b,c,d degıskenlerını tek bırlestırdı. gerıye kalan e ve sayı1 degıskenlerı ortak olmadıgı ıcın bırlesme olmadı join fonksiyonu sayesınde.
#       a     b     c     d
# 0     6     1    13    14
# 1    33    40    45    44
# 2    32   178    45    99
# 3  1514  1131  1201  1648
# 4   809  2704  2349   149
# 5    56    51    63    64
# 6    83    90    95    94
# 7    82   228    95   149
# 8  1564  1181  1251  1698
# 9   859  2754  2399   199




# 136. video son dksını anlayaamadım.
# ??????????????????
# print(pd.concat([p7,p8], ignore_index=True, join_axes=[p7.columns])) 
# ??????????????????????







#merge()
import numpy as np
import pandas as pd
h1={
    "kişiler":["kahraman","bayram","onurhan","ali"],
    "Alan":["veribilimi","DijitalPazarlama","yazılım","pazarlama"]
    }

h2={
    "kişiler":["kahraman","bayram","onurhan","ali"],
    "işeGiris":[2024,2022,2023,2025]
    }

h3=pd.DataFrame(h1)
h4=pd.DataFrame(h2)
# h5=pd.concat([h3,h4]) # bunu yazdırısak cok sacma bıcımde bırlesır.  cunku cogu sey oratk degıl.
# print(pd.merge(h3,h4)) # merge fonksiyonu kendisi  her ıkıınde ortak olan degıskenı anlayıp boylece bırlestırm yapar.
#     kişiler              Alan  işeGiris
# 0  kahraman        veribilimi      2024
# 1    bayram  DijitalPazarlama      2022
# 2   onurhan           yazılım      2023
# 3       ali         pazarlama      2025






import numpy as np
import pandas as pd
l1={
    "kişiler":["kahraman","kahraman","bayram","onurhan","ali"],
    "Alan":["veribilimi","DijitalPazarlama","DijitalPazarlama","yazılım","pazarlama"]
    }

l2={
    "Alan":["veribilimi","DijitalPazarlama","DijitalPazarlama","yazılım"],
    "Dal":["mat","ekonomi","finans","kod"]
    }

l3=pd.DataFrame(l1)
l4=pd.DataFrame(l2)
# zaten merge fonksiyonu hangisi üzerinde birleşme yapacağını biliyor ama sen yine kendi isteğinle seçmek istiyorsan o zaman print(pd.merge(h3,h4,on="Alan)) on ile belirtirsin.
print(pd.merge(l3,l4))














#GRUPLAMA İŞLEMLERİ:
import seaborn as sns # seaborn kütüphanesinden sns çağırıldı.
r1=sns.load_dataset("planets") # load_dataset veriyi yükle demek. hangi veriyi yüklemek istersin planets dedik.
print(r1)
#                method  number  orbital_period   mass  distance  year
# 0     Radial Velocity       1      269.300000   7.10     77.40  2006
# 1     Radial Velocity       1      874.774000   2.21     56.95  2008
# 2     Radial Velocity       1      763.000000   2.60     19.84  2011
# 3     Radial Velocity       1      326.030000  19.40    110.62  2007
# 4     Radial Velocity       1      516.220000  10.50    119.47  2009
# ...               ...     ...             ...    ...       ...   ...
# 1030          Transit       1        3.941507    NaN    172.00  2006
# 1031          Transit       1        2.615864    NaN    148.00  2007
# 1032          Transit       1        3.191524    NaN    174.00  2007
# 1033          Transit       1        4.125083    NaN    293.00  2008
# 1034          Transit       1        4.187757    NaN    260.00  2008


print(r1.head()) # sadece ilk bes tanesi gelir.

print(r1.shape)
print(r1.mean()) 
print(r1["mass"].mean()) # 2.6381605847953216 bu mass değişkenin ortalamasını verir.
print(r1["distance"].max()) # 8500.0 bu distance değişkeninde max değeri verir.
print(r1["mass"].sum()) # mass değişkeninin toplam değerini verdi.

print(r1.describe()) # asağıda goruldugu uzere yukarda tek tek degıskenlerın ozellıklerını belırtmek yerıne describe sayesinde hepsini gorebildik. print(r1.describe().T) bu da aynı sonucu verır ama ters halı ıle verır.

#             number  orbital_period        mass     distance         year
# count  1035.000000      992.000000  513.000000   808.000000  1035.000000
# mean      1.785507     2002.917596    2.638161   264.069282  2009.070531
# std       1.240976    26014.728304    3.818617   733.116493     3.972567
# min       1.000000        0.090706    0.003600     1.350000  1989.000000
# 25%       1.000000        5.442540    0.229000    32.560000  2007.000000
# 50%       1.000000       39.979500    1.260000    55.250000  2010.000000
# 75%       2.000000      526.005000    3.040000   178.500000  2012.000000
# max       7.000000   730000.000000   25.000000  8500.000000  2014.000000





import seaborn as sns
import pandas as pd
okul={"GRUP":["A","B","C","A","B","C"],
      "OGRENCİ":[20,50,4,12,21,30]}
df1=pd.DataFrame(okul)
print(df1)
#   GRUP  OGRENCİ
# 0    A       20
# 1    B       50
# 2    C        4
# 3    A       12
# 4    B       21
# 5    C       30

print(df1.groupby("GRUP")) # <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f0a3039ce50> burada df1 dataframında grup altında ki kategorık sınıflar olan A,B,C....tut dedik.

print(df1.groupby("GRUP").mean()) #GRUP değişkenin altında ki sınıfsal kategorık olan A,B,C nin ortalamasını verdi.
#       OGRENCİ
# GRUP         
# A        16.0
# B        35.5
# C        17.0


print(df1.groupby("GRUP").sum())
#       OGRENCİ
# GRUP         
# A          32
# B          71
# C          34



import seaborn as sns
r1=sns.load_dataset("planets")
print(r1.groupby("method")) # print(df1.groupby("GRUP")) benim yukarıda k işlemi yaptırdık aslında. şimdi aşagıda neyın ortalamaını almak ıstıyorsak onu da eklemmız gerekır.
print(r1.groupby("method")["year"].mean())
# method
# Astrometry                       2011.500000
# Eclipse Timing Variations        2010.000000
# Imaging                          2009.131579
# Microlensing                     2009.782609
# Orbital Brightness Modulation    2011.666667
# Pulsar Timing                    1998.400000
# Pulsation Timing Variations      2007.000000
# Radial Velocity                  2007.518987
# Transit                          2011.236776
# Transit Timing Variations        2012.500000
# Name: year, dtype: float64

print(r1.groupby("method")["distance"].sum())
# method
# Astrometry                           35.75
# Eclipse Timing Variations          1261.44
# Imaging                            2166.91
# Microlensing                      41440.00
# Orbital Brightness Modulation      2360.00
# Pulsar Timing                      1200.00
# Pulsation Timing Variations           0.00
# Radial Velocity                   27348.11
# Transit                          134242.77
# Transit Timing Variations          3313.00
# Name: distance, dtype: float64

print(r1.groupby("method")["mass"].describe()) # tüm hepsinin özelliklerini verdi.
# method                                               
# Astrometry                       NaN     NaN    NaN  
# Eclipse Timing Variations      5.125  5.5875   6.05  
# Imaging                          NaN     NaN    NaN  
# Microlensing                     NaN     NaN    NaN  
# Orbital Brightness Modulation    NaN     NaN    NaN  
# Pulsar Timing                    NaN     NaN    NaN  
# Pulsation Timing Variations      NaN     NaN    NaN  
# Radial Velocity                1.260  3.0000  25.00  
# Transit                        1.470  1.4700   1.47  
# Transit Timing Variations        NaN     NaN    NaN 



















import seaborn as sns
import numpy as np
import pandas as pd

okul={
      "Grup":["A","B","C","A","B","C"],
      "Not1":[85,46,45,78,96,23],
      "Not2":[77,99,71,44,14,72]
      }
ty1=pd.DataFrame(okul)
print(ty1)
print(ty1.groupby("Grup")["Not1"].sum())
print(ty1.groupby("Grup")["Not2"].sum()) # topluyor.
# Grup
# A    121
# B    113
# C    143

print(ty1.groupby("Grup")["Not2"].min()) # Not2 için  A,B,C değerlerinin hangisi daha küçük ise onu alıyor.
# Grup
# A    44
# B    14
# C    71

print(ty1.groupby("Grup").max()) # burada grup belli ama degısken vermeyınce kendısı dırek her ıkı degısken ıcın max degerlerı yazıyor.
# Grup            
# A       85    77
# B       96    99
# C       45    72



#şimdi yukarıda max min gibi fonksiyonları tek tek çağırmak yerine "aggregate" kullanacagız asagıda
print(ty1)
print(ty1.groupby("Grup").aggregate([max, np.median,min]))
#       max median min  max median min
# Grup                                
# A      85   81.5  78   77   60.5  44
# B      96   71.0  46   99   56.5  14
# C      45   34.0  23   72   71.5  71

print(ty1.groupby("Grup").aggregate({"Not1": max, "Not2":min})) # farketmıssen yukarda lıste burda dict kullandık
#       Not1  Not2
# Grup            
# A       85    44
# B       96    14
# C       45    71



#filter
# bu kısımda pandasın yapamadıgı bır fıltreleme ıslemı yapmak ıstedıgımı zman verı onumuze geldıgı zaman bu verıye kendı ıstedgımız bır fonksıyon sayesınde fıltreleme işlemi yaptıracagız.
def SahsiFiltrem(x):
    return x["Not1"].std()>12 # standart sapması 12 den buyuk olanları dondur dedık Not1 değişkeni için sadece.
print(ty1.groupby("Grup").filter(SahsiFiltrem))
#   Grup  Not1  Not2
# 1    B    46    99
# 2    C    45    71
# 4    B    96    14
# 5    C    23    72

print(ty1.groupby("Grup").std())
#            Not1       Not2
# Grup                      
# A      4.949747  23.334524
# B     35.355339  60.104076
# C     15.556349   0.707107









#transform
import numpy as np
import pandas as pd
import seaborn as sns
m={
   "grup":["a","b","c","a","b","c"],
   "not1":[12,45,78,25,69,48],
   "not2":[45,61,78,64,532,33]
   }
lş1=pd.DataFrame(m)
print(lş1)

#transform işlemleri: istediğimiz işlemi değişkenlere uygular. mesela lş1*4 desem bu da bir dönüştürme işlemidir. ama kendimizin istediği bir şey yaratıp uygulamak istersek o zaman transfor kullanıyoruz.
lş2=lş1.iloc[:,1:3] # bunu yapmamızın nedeni hata vermesini engellemektir. çünkü bunu yapmadan aşağı kısmı çalıştırırsak grup sütunu int olmayıp str olduğu için hata verdi.
lş3=lş2.transform(lambda m :  (m-1/m)) # her m değişkeninden 1 çıkar ve kendisine böl daha sonra yazdır.
print(lş3)
#         not1        not2
# 0  11.916667   44.977778
# 1  44.977778   60.983607
# 2  77.987179   77.987179
# 3  24.960000   63.984375
# 4  68.985507  531.998120
# 5  47.979167   32.969697









#apply: bu da filter ve transform gibi her değişken üzerinde oynama özelliği var.
import numpy as np
import pandas as pd
# import seaborn as sns
m={
   "not1":[12,45,78,25,69,48],
   "not2":[45,61,78,64,532,33]
   }
 
lş4=pd.DataFrame(m)
print(lş4.apply(np.sum))
# not1    277
# not2    813
# dtype: int64

print(lş4.apply(np.mean))
# not1     46.166667
# not2    135.500000
# dtype: float64


n={
   "grup":["a","b","c","a","b","c"],
   "not1":[12,45,78,25,69,48],
   "not2":[45,61,78,64,532,33]
   }

lş5=pd.DataFrame(n)
print(lş5.apply(np.sum))
# grup    abcabc
# not1       277
# not2       813
# dtype: object


print(lş5.groupby("grup").apply(np.sum))
#      grup  not1  not2
# grup                 
# a      aa    37   109
# b      bb   114   593
# c      cc   126   111






