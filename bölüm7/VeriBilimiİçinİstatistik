# örnek teorisi uygulama:
import numpy as np
populasyon=np.random.randint(0,80,1000) # 0 ile 80 yaş arası 1000 seç.
print(populasyon[0:10]) # ilk 10 tanesini yazdırdım.
orneklem=np.random.choice(a=populasyon, size=100) #populasyondan rasgele 100 kişi seç.
print(orneklem.mean())
print(populasyon.mean()) # bu iki satırdan şu anlaşılıyor: orneklem ve populasyon ortalaması birbirine ne kadar yakın olduğunu görmüş olduk.





# betimsel istatistik uygulama:
import seaborn as sns
tips=sns.load_dataset("tips")
df=tips.copy()
print(df.head())

!pip install researchpy # bu sayede kütüphanemizi indirdik.
import researchpy as rp
rp.summary_cont(df[["total_bill","tip","size"]]) # summary_cont sayısal değişken seçmek için kullanılır.
rp.summary_cat(df[["sex","smoker","time"]])

print(df[["total_bill","tip"]].cov()) # bu sayede koveryans bilgisi geldi.
print(df[["total_bill","tip"]].corr()) # bu şekilde de korelasyona bakmış olduk. her ikisi arasında 0.67 lik pozitif bir ilişki var demek ki.


# güven aralıkları
import numpy as np
fiyatlar=np.random.randint(1,100,1000) # 1 ile 100 tl arasında fiyatı belirlemek için 1000 müşteriye baktığımızı varsayalım.
import statsmodels.stats.api as sms
print(sms.DescrStatsW(fiyatlar).tconfint_mean()) # demek ki 1000 kişi yüzde 95 ihtimalle çıkan bu iki değer arasında ürüne fiyat biçmiş.







# olasılık dağılımları:
# bernoulli dağılımı:
from scipy.stats import bernoulli
p=0.8
rv=bernoulli(p)
print(rv.pmf(k=0)) # k=0 ise paranın yazı gelme k=1 ise tura gelme olasılığını hesapla demiş oluyoruz.







#??????????????????????????????????????????????????????????
# büyük sayılar yasası anlaşılmadı. mustafa vahit video  187
#??????????????????????????????????????????????????????????







# binom dağılımı
from scipy.stats import binom
p=0.01
n=100
rv=binom(n,p)
print(rv.pmf(1)) # 100 kişiden 1 kişinin tıklama olasılığı
print(rv.pmf(5)) # 100 kişiden 5 kişinin tıklama olasılığı
print(rv.pmf(10)) # 100 kişiden 10 kişinin tıklama olasılığı






#poisson dağılımı. 190.video için şu videoyu izle: https://www.youtube.com/watch?v=6938zXG9FWU&t=703s
from scipy.stats import poisson
lambdaa=0.1 #(lamda ortalama hata sayısını verir.)
rv=poisson(mu=lambdaa) # mu poissonun bir argümanıdır.
print(rv.pmf(k=0)) # hiç hata olmama olasılığını bulduk.
print(rv.pmf(k=3)) # 3 hata olma olasılığını bulduk. k kaç ise o kadarını bulur.







#normal dağılım:
#diyelim ki bir iş te dağılımın normal olduğu biliniyor. aylık ortalama satış sayısı 80k ve standart sapma 5 tir. soru şu önümüzde ki ay satışların 90k dan fazla olma olasılığı nedir?
# şimdi zaten standart sapma 5 ise demek ki önümüzde ki günler de çooook yüksek olasılıkla 80-5<olasılık<80+5 civarında olur. standart sapmayı böyle kullanıyoruz.
# istersen deneyelim şimdi. 0 dan fazla olma olasılığına bak ve de 75 olma olasılığının sonucuna bak.
# tabii bu sonuçlar aslında intagral ile bulunuyor. bu integralin bu alanı burada aşağıda yazdığımız fonksiyonlar hal ediyor. 
# grafiğin altı tümü toplamı 1 sayılır.

from scipy.stats import norm
#90 dan fazla olma olasılığı:
print(1-norm.cdf(90,80,5)) # dikkkat et 1 den cıkardım fazla olma olasılıgı denildiğinde. 90 istenilen 80 normal ortalama zaten ve en sonda ki 5 ise standart sapmadır. 0.02275013194817921

# 73 ten az olma olasılığı:
print(norm.cdf(73,80,5)) # 0.08075665923377107

# 85 ile 90 arasında olma olasılığı :
print(norm.cdf(90,80,5)-norm.cdf(85,80,5)) # 0.13590512198327787




# hata ipleri. 196. video da ya da youtube da bakabilirsin.

# p-value değeri 197. video ya da youtube dan bakabilirsin.

# hipotez testleri adımları 198. video ya da youtube dan konuya bakabilirsin.

# tek örneklem T testi: 199. video ya da youtube dan gereken videoları izleyebilirsin.



# elimizde bir web sitesi var. bu sitede kullanıcıların ortalama ne kadar süre harcadıklarını bulmaya çalışacağız.
# tabii bunu belirlerken z , t testleri gibi testleri kullanacağız.mean() bize bir değer gösterir. ama bu değer belki de şansa bağlı olarak olmuştur.
# belki bilgisayar öyle değerler seçmiştir ki mean() yani ortalama değer öyle çıkmıştır. işe bu yüzden hipotez testleri vardır. bu testler ile bizler şansı en aza indererk yüzde 95 doğruluk payı ile gerçek te web sitesinde geçirilen değeri bulmaya çalışıyoruz.


import numpy as np
import scipy.stats as stats
# web sitesinde geçirilen süreleri böyle bir array haline getirdik. ama normalde bu bize csv modunda gelipte okuyabilirdik.
olcumler=np.array([45,78,79,28,49,76,33,42,41,71,81,61,62,86,96,654]) # bu biim örneklememiz de ki ölçümler. bunlara bakarak daha genel bir sonuç çıkarmakyaya yarar. mesela 1000 nufuslu ılcede 100 kişinin değerleerine bakılması da bır orneklemdır.
print(stats.describe(olcumler)) # DescribeResult(nobs=16, minmax=(28, 654), mean=98.875, variance=22327.983333333334, skewness=3.500184345920849, kurtosis=10.557917648609019)
# görüldüğü üzere ortlama geçirilen süre mean() = 98 saniye denilebilir. ama bu şansa bağlı olarakta gerçekleşmiş olabilir. bu yüzden sonra ki adımımız hipotez testlerine geçmek olacaktır.
# H0=fark yoktur.... burada h0 ve h1 diye hipotez kurduk. orneklem ile teorik te ki değerler arasında ki fark için fark vardır ya da yoktur dedik. bunu öğrenmek için ise pylab ya da shapiro tetslerini kullanıp dağılımda fark olup olmadığına bakacağız. böylece fark yoksa h0 reddedilmez. fark var ise h0 red edilir.
# H1=fark vardır.... bu arada orneklem ve teorik dedik burda kş teorik şu oluyor: orneklem ilcede ki 100 işi iken teorik gercek ilcedeki 1000 kişinin değerleridir.
# şimdi ise bu 98 değeri şansa bağlı olup olmadığını öğrenmek için hipotez testlerine geçmemiz gerekiyor. ama daha geçmeden önce "varsayımlar kısmı var"
# varsayımlar
import pylab
stats.probplot(olcumler, dist="norm",plot="pylab")
print(pylab.show()) # şimdi bu grafikte sol değerler 


# web site yoneticisi bizden gecırılen surenın 98 olup olmadıgını soruyor ortalamaya baktık ve 98 cıktı ama biz yıne şansa baglıdır belkı dıyıp hıpotez testlerine gectık.

# shapiro-wilk testi: dağılım normal olup olmadığını gösterir. eğer dağılım normal ise t testi uygulanabilir.
from scipy.stats import shapiro # aşağıda bize 2 değer verildi. sağda ki pvalue değeri gördüğümüz üzere.
print(shapiro(olcumler)) # ShapiroResult(statistic=0.39786744117736816, pvalue=3.374176742454438e-07) . eğer pvalue değeri 0.05 den küçükse h0 red ediyoruz. değilse h0 ret edemiyoruz.
# karmakarıık grafiklere bakmak yerine sadece pvalue değerine bakarak h0 ın red edilip edilmeyecegını gorebılır. burda mesela 0.05 ten buyuk oldugu h0 red edılmez. 
# h0 red edilmediği içinde tek orneklem t testi kullanılır.



# shapiro ile dağılımın normal olduğu belirlendi bu yüzden artık burada hipotez kımına geçip t testini uyguladık. eger p-value 0.05 ten kucuk olsaydı o zaman asagıda kı nonparametrik test uygulanırdı.
# hipotez testinin uygulanması:

# h0=web sitesinde gecirilen ortalama süre 98 saniyedir.
# h1=web sitesinde gecirilen ortalama süre 98 saniye değildir.
print(stats.ttest_1samp(olcumler,popmean=98)) # web sitesinde gecirilen ortalama süre 98 mi? diye sormuş olduk.
# Ttest_1sampResult(statistic=0.023423041868234133, pvalue=0.03) # sonucu baktığımızda  plavlue degeri 0.05 ten kucuk yanı h0 degeri red edilmeli. yani web sitesinde gecirilen ortalama sure demek ki 98 den farklıdır. demek ki 98 şans eseri olmuş demektir.





# Nonparametrik tek örneklem testi 
# eğer bizim daha önce yaptığımız normallik dağılımı normal dağılmamış olsaydı ya da pvalue değeri 0.05 ten küçük olsaydı o zman nonparametrik tek orneklem testi kullanırdık. 
from statsmodel.stats.descriptivestats import sign_test  
sign_test(olcumler,98)









#tek örneklem oran testi:  
 
# elimizde bir dönüşüm oranı var. bu oran 0.125 denilmiş. bu dönüşüm oranı reklam olarak alınabilir mesela.  
# ama biz bundan şüphe duyduğumuz için bunu test etmemiz gerekir. ve de elimzde şu var: 500 ziyaretten 40 kişi ürünü satın almış. 
 
# H0:p=0.125 
# H1:p!=0.125 # hiipotezleri şu şekilde koyduk. 
from statsmodels.stats.proportion import proportions_ztest 
count=40 
nobs=500 
value=0.125 # bu bizim test etmek istediğimiz değer. bunu value diyoruz. 
# print(proportions_ztest(count,nobs,value)) değerler bu sıra ile girilmesi gerekir. 
print(proportions_ztest(40,500,0.125)) # (-3.7090151628513017, 0.0002080669689845979) 
#çıkan sonucta yıne ıkıncı sonuc pvalue degeri oluyor. 
# ve de 0.05 ten küçük oldugu ıcın h0 red edilir. yanı donusum oranı demek kı 0.125 ten farklı imiş. bu yüzde 95 ihtimalle boyle tabıı ki her zman dedıgımız gıbı.











from abc import ABC 
# Bağımsız iki örneklem t testi:(AB testi): iki grup orantıları arasında karşılaştırma yapmak için kullanılır. 
# ML(makine ögrenmesı) modelinin basarı testı 
# biz şirkette bir veribilimci işe aldık ve ondan sistemi makine ogrenmesı yoluyla geliştirmesini istedik. AB testinde amacımız yaptıgımız degısıkler sonucu eskı sıstem ve yenı sısteme baktıgımız zmana yenı sıstem de bır degısıklık olup olmadıgını saptmak . 
# ML modeli anlamlı bır farklılık oluşturabildi mi? 
# h0:u1=u2 # insanlar ürün alırken makine ogrenımı yoluyla urun alımında degısıklık yaratabılındı. asagıda ki ise yaratılmadı denılıyor. 
# h1:u1!=u2 
import numpy as np 
import pandas as pd 
a=np.random.randint(1,100,20) 
b=np.random.randint(25,200,20) 
A=pd.DataFrame(a) 
B=pd.DataFrame(b) # burada ki A eski sistemin gelen gelirlerini B ise yeni sistemin gelirlerini gösterir.  
A_B=pd.concat([A,B],axis=1) 
A_B.columns=["A","B"] 
print(A_B)  
 
 
 
import seaborn as sns 
print(sns.boxplot(x=A, y=A_B,data=A))
